#-------------------------------------------------------------------------
#(4)going to compare the "event" and "non-event" site
#-------------------------------------------------------------------------
#-------------------------------------------------------------------------
#start plotting
#-------------------------------------------------------------------------
library(plyr)
library(ggplot2)
library(cowplot)
library(grid)
#function used to compare the "event" and "non_event" sites using geom_ribbon
#source the comparsion test written by me:
fun.path<-"D:/Github/photocold_lyp/R/Step2_identify_events/Functions/functions_from_YP/"
source(paste0(fun.path,"Difference_test_for_2Classes.R"))
plot_2groups<-function(df,comp_var,var_unit,do_norm,do_legend){
# df<-df_len5_nonnorm
# comp_var<-"TS_top3_fluxnet2015"
# var_unit<-"degC"
# do_norm<-FALSE
# do_legend<-TRUE
#
df.event<-df$df_dday
df.noevent<-df$df_noevent_dday
#------------------------------------
#remove the sites that have the point numbers smaller than 10
#------------------------------------
N_value<-ddply(df.noevent,.(sitename),summarise,N=length(date))
rm_sites<-subset(N_value,N<10)
if(nrow(rm_sites)>=1){
for(i in nrow(rm_sites)){
rm_site_name<-rm_sites[i]
df.noevent<-df.noevent[df.noevent$sitename!=as.character(rm_site_name),]
}
}
df.noevent<-df.noevent
#--------------------------------
#selected the most relevant vars
#for the comparison,select the original variable if "do_norm"==FALSE,otherwise "do_norm"==TRUE
#--------------------------------
if(do_norm==FALSE){
df.event_sel<-df.event[,c("sitename","Year","date","dday",comp_var)]
names(df.event_sel)<-c("sitename","Year","date","dday","comp_var")
df.nonevent_sel<-df.noevent[,c("sitename","Year","date","dday",comp_var)]
names(df.nonevent_sel)<-c("sitename","Year","date","dday","comp_var")
}
if(do_norm==TRUE){
comp_var_norm<-paste0("ds",comp_var)
df.event_sel<-df.event[,c("sitename","Year","date","dday",comp_var_norm)]
names(df.event_sel)<-c("sitename","Year","date","dday","comp_var")
#
df.nonevent_sel<-df.noevent[,c("sitename","Year","date","dday",comp_var_norm)]
names(df.nonevent_sel)<-c("sitename","Year","date","dday","comp_var")
#also make var_unit()==""
var_unit<-c()
}
#--------------------------------------
#plotting
#--------------------------------------
# Create a text
grob_event <- grobTree(textGrob("Event site-year", x=0.6,  y=0.9, hjust=0,
gp=gpar(col="red", fontsize=18, fontface="italic")))
# grob_event_name <- grobTree(textGrob(df_name, x=0.8,  y=0.1, hjust=0,
#                                      gp=gpar(col="red", fontsize=18, fontface="italic")))
grob_nonevent <- grobTree(textGrob("Non-Event site-year", x=0.6,  y=0.9, hjust=0,
gp=gpar(col="green4", fontsize=18, fontface="italic")))
# grob_nonevent_name<-grobTree(textGrob(df_name, x=0.8,  y=0.1, hjust=0,
#                                       gp=gpar(col="red", fontsize=18, fontface="italic")))
#y axis range:
ymin<-min(range(df.event_sel$comp_var,na.rm = T),range(df.nonevent_sel$comp_var,na.rm = T))
ymax<-max(range(df.event_sel$comp_var,na.rm = T),range(df.nonevent_sel$comp_var,na.rm = T))
#x axis range
# x_range_event<-range(df.event_sel$doy)
# x_range_nonevent<-range(df.nonevent_sel$doy)
###start to make the quantiile plot:
##2022,Aug-->change the "GPP overestimated sites" to "SY_PSB", the other to "SY_ASB"
# df.event_sel$flag<-rep("GPP overestimated sites",nrow(df.event_sel))
# df.nonevent_sel$flag<-rep("GPP non-overestimated sites",nrow(df.nonevent_sel))
df.event_sel$flag<-rep("SY_PSB",nrow(df.event_sel))
df.nonevent_sel$flag<-rep("SY_ASB",nrow(df.nonevent_sel))
#!one thing need to pay attention-->use q90 to limit the dday range in sites as the sites diff a lot
#to ensure the results do not impact by one specific site
dday_range_event<-ddply(df.event_sel,.(sitename),summarize,min_dday=min(dday),max_dday=max(dday))
dday_range_nonevent<-ddply(df.nonevent_sel,.(sitename),summarize,min_dday=min(dday),max_dday=max(dday))
sel_dday_event<-floor(quantile(dday_range_event$max_dday,0.75))
sel_dday_nonevent<-floor(quantile(dday_range_nonevent$max_dday,0.75))
#
df.event_sel<-df.event_sel[df.event_sel$dday<=sel_dday_event,]
df.nonevent_sel<-df.nonevent_sel[df.nonevent_sel$dday<=sel_dday_nonevent,]
##merge and classify
df.all<-rbind(df.event_sel,df.nonevent_sel)
df.all$flag<-factor(df.all$flag,levels = c("SY_PSB","SY_ASB"))
##
#for min temperature-->first find the mininum temperature for each site then calculate the quantile
if(comp_var=="temp_min_fluxnet2015"){
df.all<-df.all %>%
group_by(sitename,dday,flag) %>%
dplyr::summarise(comp_var=min(comp_var,na.rm = T))
}
#merge the different sites in "event" and "non-event" sites->calculate the quantiles at the same time
df.all_q<-ddply(df.all,.(flag,dday),summarize,q10=quantile(comp_var,0.1,na.rm = T),q25=quantile(comp_var,0.25,na.rm = T),
q50=quantile(comp_var,0.5,na.rm = T),q75=quantile(comp_var,0.75,na.rm = T),q90=quantile(comp_var,0.9,na.rm = T))
#-----------------------
#add a additional test-->to compare if the vars are significant different(q50) in two categories
#----------------------
compare_diff<-function(df_comp,sel_perc,flag){
# df_comp<-df.all
# sel_perc<-1             #which period (percentage of the minimum days) used to compare between vars in two category
# flag<-"all"
df_comp_event<-df_comp[df_comp$flag=="SY_PSB",]
df_comp_nonevent<-df_comp[df_comp$flag=="SY_ASB",]
#------
#select the data
#------
range_dday_event<-range(df_comp_event$dday)
range_dday_nonevent<-range(df_comp_nonevent$dday)
range_sel<-c(min(range_dday_event[1],range_dday_nonevent[1]),
floor(sel_perc*min(range_dday_event[2],range_dday_nonevent[2])))
#
df_comp_event_sel<-subset(df_comp_event,dday>=range_sel[1]&dday<=range_sel[2])
df_comp_nonevent_sel<-subset(df_comp_nonevent,dday>=range_sel[1]&dday<=range_sel[2])
#additional-->for before events(b0):
df_comp_event_b0<-subset(df_comp_event,dday>=range_sel[1]&dday<=0)
df_comp_nonevent_b0<-subset(df_comp_nonevent,dday>=range_sel[1]&dday<=0)
#make the statistical comparision:
if(flag=="q50"){
stat.test_1<-difftest_function(df_comp_event_sel$q50,df_comp_nonevent_sel$q50)
stat.test_2<-difftest_function(df_comp_event_b0$q50,df_comp_nonevent_b0$q50)
stat.test<-cbind(stat.test_1,stat.test_2)
names(stat.test)<-c("All selecte period","Before events")
}
if(flag=="all"){
stat.test_1<-difftest_function(df_comp_event_sel$comp_var,df_comp_nonevent_sel$comp_var)
stat.test_2<-difftest_function(df_comp_event_b0$comp_var,df_comp_nonevent_b0$comp_var)
stat.test<-cbind(stat.test_1,stat.test_2)
names(stat.test)<-c("All selecte period","Before events")
}
return(stat.test)
}
#
stat.alldata_for2<-compare_diff(df.all,1,"all")
stat.q50_for2<-compare_diff(df.all_q,1,"q50")
#making the quantile plot using ribbon function:
p_plot<-ggplot(df.all_q)+
# annotate("rect",xmin=0,xmax=max(df.all_q$dday),ymin = -Inf,ymax = Inf,alpha=0.2)+
#some changes here
annotate("rect",xmin=0,xmax=70,ymin = -Inf,ymax = Inf,alpha=0.2)+
geom_line(aes(x=dday,y=q50,col=flag),size=1.05)+
scale_color_manual("",values = c("SY_PSB"="red","SY_ASB"="blue"))+
# geom_ribbon(aes(x=dday,ymin=q10,ymax=q90,fill=flag),alpha=0.15)+
geom_ribbon(aes(x=dday,ymin=q25,ymax=q75,fill=flag),alpha=0.4)+
scale_fill_manual("",values = c("SY_PSB"="red","SY_ASB"="dodgerblue"))+
ylab(paste0(comp_var," ",var_unit))+
xlab("gday")+
theme_classic()+
theme(legend.position = c(0.3,0.9),legend.background = element_blank(),
legend.key.size = unit(2, 'lines'),
legend.text = element_text(size=20),
axis.title = element_text(size=24),
axis.text = element_text(size = 20))+
xlim(-60,70)  #add x range in 2021-09-25
#legend
if(do_legend==FALSE){
p_plot<-p_plot+
theme(legend.position = "none")
}
# print(p_plot)
#returun object
out<-c()
out$stats_q50<-stat.q50_for2
out$stats_alldata<-stat.alldata_for2
out$plot<-p_plot
return(out)
}
#2021-09-25:check the temp_min,temp_max,temp_day, and LUE
#update in 2021-11-16:update the gpp_obs, gpp_biaes
#--------------
#I.GPP and LUE
#-------------
#gpp_obs
p_gpp_obs_len5_b60<-plot_2groups(df_len5_nonnorm,"gpp_obs","(umol m-2 s-1)",do_norm = FALSE,do_legend = TRUE)
#gpp biaes
p_gpp_biaes_len5_b60<-plot_2groups(df_len5_nonnorm,"gpp_res","(umol m-2 s-1)",do_norm = FALSE,FALSE)
#LUE
p_LUE_len5_b60<-plot_2groups(df_len5_nonnorm,"LUE","",do_norm = FALSE,FALSE)
#for ppfd: change the "ppfd_fluxnet2015" to "PPFD_IN_fullday_mean_fluxnet2015"
# p_ppfd_len5_b60<-plot_2groups(df_len5_nonnorm,"ppfd_fluxnet2015","(u mol m-2 s-1)",do_norm = FALSE,do_legend = TRUE)
p_ppfd_len5_b60<-plot_2groups(df_len5_nonnorm,"PPFD_IN_fullday_mean_fluxnet2015","(u mol m-2 s-1)",do_norm = FALSE,do_legend = TRUE)
#fapar_spl and fapar_itpl
p_fapar_itpl_len5_b60<-plot_2groups(df_len5_nonnorm,"fapar_itpl","",do_norm = FALSE,do_legend = FALSE)
#some modifying in the plot:
p_gpp_obs_len5_b60$plot<-p_gpp_obs_len5_b60$plot+
xlab("")+
ylab(expression("GPP"[obs]*" (g "*"m"^-2*" d"^-1*")"))
p_gpp_biaes_len5_b60$plot<-p_gpp_biaes_len5_b60$plot+
xlab("")+
ylab(expression("GPP bias"*" (g "*"m"^-2*" d"^-1*")"))
p_ppfd_len5_b60$plot<-p_ppfd_len5_b60$plot+
# xlab("dday")+
ylab(expression("PAR"*" (u mol "*"m"^-2*" s"^-1*")"))
p_fapar_itpl_len5_b60$plot<-p_fapar_itpl_len5_b60$plot+
xlab("")+
ylab("fapar")
#--------------
#II.Environment variables
#note by YP 2021-11-21:
#-->there is no temp_min/temp_max,SW_IN,TS_1,SWC_1 data for original Fluxnet2015 data tidied from Beni
#-------------
#temp_day
p_temp_day_len5_b60<-plot_2groups(df_len5_nonnorm,"temp_day_fluxnet2015","(degreeC)",do_norm = FALSE,TRUE)
#temp_min
p_temp_min_len5_b60<-plot_2groups(df_len5_nonnorm,"temp_min_fluxnet2015","(degreeC)",do_norm = FALSE,do_legend = FALSE)
#temp_max
p_temp_max_len5_b60<-plot_2groups(df_len5_nonnorm,"temp_max_fluxnet2015","(degreeC)",do_norm = FALSE,FALSE)
#for prec
p_prec_len5_b60<-plot_2groups(df_len5_nonnorm,"prec_fluxnet2015","(mm)",do_norm = FALSE,do_legend = FALSE)
#vpd_day
p_vpd_day_len5_b60<-plot_2groups(df_len5_nonnorm,"vpd_day_fluxnet2015","(Pa)",do_norm = FALSE,do_legend = FALSE)
#SW_IN
p_SW_IN_len5_b60<-plot_2groups(df_len5_nonnorm,"SW_IN_fullday_mean_fluxnet2015","(W m-2)",do_norm = FALSE,FALSE)
#TS_1-->first layer soil temperature
p_TS_1_len5_b60<-plot_2groups(df_len5_nonnorm,"TS_1_fluxnet2015","(degreeC)",do_norm = FALSE,FALSE)
#SWC_1-->first layer soil mosture
p_SWC_1_len5_b60<-plot_2groups(df_len5_nonnorm,"SWC_1_fluxnet2015","(%)",do_norm = FALSE,FALSE)
#SWC_1-->first layer soil mosture
p_SWC_top3_len5_b60<-plot_2groups(df_len5_nonnorm,"SWC_top3_fluxnet2015","(%)",do_norm = FALSE,FALSE)
#SWC_1-->first layer soil mosture
p_SWC_top3_len5_b60<-plot_2groups(df_len5_nonnorm,"TS_top3_fluxnet2015","(%)",do_norm = FALSE,FALSE)
df_len5_nonnorm$df_dday$TS
p_SWC_top3_len5_b60$plot
p_TS_1_len5_b60$plot
p_SWC_2_len5_b60<-plot_2groups(df_len5_nonnorm,"TS_2_fluxnet2015","(%)",do_norm = FALSE,FALSE)
#SWC_1-->first layer soil mosture
p_TS_top3_len5_b60<-plot_2groups(df_len5_nonnorm,"TS_top3_fluxnet2015","(%)",do_norm = FALSE,FALSE)
p_TS_2_len5_b60<-plot_2groups(df_len5_nonnorm,"TS_2_fluxnet2015","(%)",do_norm = FALSE,FALSE)
p_TS_2_len5_b60$plot
p_TS_3_len5_b60<-plot_2groups(df_len5_nonnorm,"TS_3_fluxnet2015","(%)",do_norm = FALSE,FALSE)
p_TS_3_len5_b60$plot
p_TS_top3_len5_b60$plot
visdat::vis_miss(df_len5_nonnorm$df_dday, warn_large_data = FALSE)
#check the data aviablity for each variable:
library(visdat)
install.packages("visdat")
visdat::vis_miss(df_len5_nonnorm$df_dday, warn_large_data = FALSE)
pos_TS<-grep("TS_",names(df_len5_nonnorm$df_dday))
pos_TS
visdat::vis_miss(df_len5_nonnorm$df_dday[,pos_TS], warn_large_data = FALSE)
visdat::vis_miss(df_len5_nonnorm$df_dday[,pos_TS], warn_large_data = FALSE)
ttt_a<-df_proc[!is.na(df_proc$TS_2_fluxnet2015),c("TS_1_fluxnet2015",
"TS_2_fluxnet2015","TS_3_fluxnet2015")]
ttt<-df_proc[,c("TS_1_fluxnet2015",
"TS_2_fluxnet2015","TS_3_fluxnet2015")]
rowMeans(df_proc[!is.na(df_proc$TS_2_fluxnet2015),c("TS_1_fluxnet2015",
"TS_2_fluxnet2015","TS_3_fluxnet2015")],na.rm=T)
#(3)calculating some important variables like LUE...
#-------------------------------------------------------------------------
#--------------------------
#calculating more variables
#--------------------------
#1)LUE=GPP/fAPAR*ppfd
#unit-->GPP: umol m-2 s-1; ppdf-->umol m-2 s-1; fAPRA: unitless
#2)GRVI=(gcc-rcc)/c(gcc+rcc)
#3)albedo:alpha_SW<-SW_OUT/SW_IN; alpha_ppdf<-PPFD_IN/PPFD_OUT
#4)approximated fAPARchl=EVI*factor(factor = 1)
for(i in 1:length(df_len5_nonnorm)){
#
df_proc<-df_len5_nonnorm[[i]]
df_proc$LUE<-df_proc$gpp_obs/c(df_proc$fapar_itpl*df_proc$PPFD_IN_fullday_mean_fluxnet2015)
df_proc$GRVI<-c(df_proc$gcc_90-df_proc$rcc_90)/c(df_proc$gcc_90+df_proc$rcc_90)
df_proc$alpha_SW<-df_proc$SW_OUT_fullday_mean_fluxnet2015/df_proc$SW_IN_fullday_mean_fluxnet2015
df_proc$alpha_PPFD<-df_proc$PPFD_OUT_fullday_mean_fluxnet2015/df_proc$PPFD_IN_fullday_mean_fluxnet2015
df_proc$fAPAR_chl<-df_proc$evi*1
##adding the mean values of soil mositure of first 3 layers:
df_proc$TS_top3_fluxnet2015<-rowMeans(df_proc[!is.na(df_proc$TS_2_fluxnet2015),c("TS_1_fluxnet2015",
"TS_2_fluxnet2015","TS_3_fluxnet2015")],na.rm=T)
#assign value back:
df_len5_nonnorm[[i]]<-df_proc
}
#(3)calculating some important variables like LUE...
#-------------------------------------------------------------------------
#--------------------------
#calculating more variables
#--------------------------
#1)LUE=GPP/fAPAR*ppfd
#unit-->GPP: umol m-2 s-1; ppdf-->umol m-2 s-1; fAPRA: unitless
#2)GRVI=(gcc-rcc)/c(gcc+rcc)
#3)albedo:alpha_SW<-SW_OUT/SW_IN; alpha_ppdf<-PPFD_IN/PPFD_OUT
#4)approximated fAPARchl=EVI*factor(factor = 1)
for(i in 1:length(df_len5_nonnorm)){
#
df_proc<-df_len5_nonnorm[[i]]
df_proc$LUE<-df_proc$gpp_obs/c(df_proc$fapar_itpl*df_proc$PPFD_IN_fullday_mean_fluxnet2015)
df_proc$GRVI<-c(df_proc$gcc_90-df_proc$rcc_90)/c(df_proc$gcc_90+df_proc$rcc_90)
df_proc$alpha_SW<-df_proc$SW_OUT_fullday_mean_fluxnet2015/df_proc$SW_IN_fullday_mean_fluxnet2015
df_proc$alpha_PPFD<-df_proc$PPFD_OUT_fullday_mean_fluxnet2015/df_proc$PPFD_IN_fullday_mean_fluxnet2015
df_proc$fAPAR_chl<-df_proc$evi*1
##adding the mean values of soil mositure of first 3 layers:
df_proc$TS_top3_fluxnet2015<-rowMeans(df_proc[,c("TS_1_fluxnet2015",
"TS_2_fluxnet2015","TS_3_fluxnet2015")])
#assign value back:
df_len5_nonnorm[[i]]<-df_proc
}
#check the data aviablity for each variable:
library(visdat)
pos_TS<-grep("TS_",names(df_len5_nonnorm$df_dday))
visdat::vis_miss(df_len5_nonnorm$df_dday[,pos_TS], warn_large_data = FALSE)
visdat::vis_miss(df_len5_nonnorm$df_dday[,pos_TS], warn_large_data = FALSE)
#-------------------------------------------------------------------------
#(4)going to compare the "event" and "non-event" site
#-------------------------------------------------------------------------
#-------------------------------------------------------------------------
#start plotting
#-------------------------------------------------------------------------
library(plyr)
library(ggplot2)
library(cowplot)
library(grid)
#function used to compare the "event" and "non_event" sites using geom_ribbon
#source the comparsion test written by me:
fun.path<-"D:/Github/photocold_lyp/R/Step2_identify_events/Functions/functions_from_YP/"
source(paste0(fun.path,"Difference_test_for_2Classes.R"))
plot_2groups<-function(df,comp_var,var_unit,do_norm,do_legend){
# df<-df_len5_nonnorm
# comp_var<-"TS_top3_fluxnet2015"
# var_unit<-"degC"
# do_norm<-FALSE
# do_legend<-TRUE
#
df.event<-df$df_dday
df.noevent<-df$df_noevent_dday
#------------------------------------
#remove the sites that have the point numbers smaller than 10
#------------------------------------
N_value<-ddply(df.noevent,.(sitename),summarise,N=length(date))
rm_sites<-subset(N_value,N<10)
if(nrow(rm_sites)>=1){
for(i in nrow(rm_sites)){
rm_site_name<-rm_sites[i]
df.noevent<-df.noevent[df.noevent$sitename!=as.character(rm_site_name),]
}
}
df.noevent<-df.noevent
#--------------------------------
#selected the most relevant vars
#for the comparison,select the original variable if "do_norm"==FALSE,otherwise "do_norm"==TRUE
#--------------------------------
if(do_norm==FALSE){
df.event_sel<-df.event[,c("sitename","Year","date","dday",comp_var)]
names(df.event_sel)<-c("sitename","Year","date","dday","comp_var")
df.nonevent_sel<-df.noevent[,c("sitename","Year","date","dday",comp_var)]
names(df.nonevent_sel)<-c("sitename","Year","date","dday","comp_var")
}
if(do_norm==TRUE){
comp_var_norm<-paste0("ds",comp_var)
df.event_sel<-df.event[,c("sitename","Year","date","dday",comp_var_norm)]
names(df.event_sel)<-c("sitename","Year","date","dday","comp_var")
#
df.nonevent_sel<-df.noevent[,c("sitename","Year","date","dday",comp_var_norm)]
names(df.nonevent_sel)<-c("sitename","Year","date","dday","comp_var")
#also make var_unit()==""
var_unit<-c()
}
#--------------------------------------
#plotting
#--------------------------------------
# Create a text
grob_event <- grobTree(textGrob("Event site-year", x=0.6,  y=0.9, hjust=0,
gp=gpar(col="red", fontsize=18, fontface="italic")))
# grob_event_name <- grobTree(textGrob(df_name, x=0.8,  y=0.1, hjust=0,
#                                      gp=gpar(col="red", fontsize=18, fontface="italic")))
grob_nonevent <- grobTree(textGrob("Non-Event site-year", x=0.6,  y=0.9, hjust=0,
gp=gpar(col="green4", fontsize=18, fontface="italic")))
# grob_nonevent_name<-grobTree(textGrob(df_name, x=0.8,  y=0.1, hjust=0,
#                                       gp=gpar(col="red", fontsize=18, fontface="italic")))
#y axis range:
ymin<-min(range(df.event_sel$comp_var,na.rm = T),range(df.nonevent_sel$comp_var,na.rm = T))
ymax<-max(range(df.event_sel$comp_var,na.rm = T),range(df.nonevent_sel$comp_var,na.rm = T))
#x axis range
# x_range_event<-range(df.event_sel$doy)
# x_range_nonevent<-range(df.nonevent_sel$doy)
###start to make the quantiile plot:
##2022,Aug-->change the "GPP overestimated sites" to "SY_PSB", the other to "SY_ASB"
# df.event_sel$flag<-rep("GPP overestimated sites",nrow(df.event_sel))
# df.nonevent_sel$flag<-rep("GPP non-overestimated sites",nrow(df.nonevent_sel))
df.event_sel$flag<-rep("SY_PSB",nrow(df.event_sel))
df.nonevent_sel$flag<-rep("SY_ASB",nrow(df.nonevent_sel))
#!one thing need to pay attention-->use q90 to limit the dday range in sites as the sites diff a lot
#to ensure the results do not impact by one specific site
dday_range_event<-ddply(df.event_sel,.(sitename),summarize,min_dday=min(dday),max_dday=max(dday))
dday_range_nonevent<-ddply(df.nonevent_sel,.(sitename),summarize,min_dday=min(dday),max_dday=max(dday))
sel_dday_event<-floor(quantile(dday_range_event$max_dday,0.75))
sel_dday_nonevent<-floor(quantile(dday_range_nonevent$max_dday,0.75))
#
df.event_sel<-df.event_sel[df.event_sel$dday<=sel_dday_event,]
df.nonevent_sel<-df.nonevent_sel[df.nonevent_sel$dday<=sel_dday_nonevent,]
##merge and classify
df.all<-rbind(df.event_sel,df.nonevent_sel)
df.all$flag<-factor(df.all$flag,levels = c("SY_PSB","SY_ASB"))
##
#for min temperature-->first find the mininum temperature for each site then calculate the quantile
if(comp_var=="temp_min_fluxnet2015"){
df.all<-df.all %>%
group_by(sitename,dday,flag) %>%
dplyr::summarise(comp_var=min(comp_var,na.rm = T))
}
#merge the different sites in "event" and "non-event" sites->calculate the quantiles at the same time
df.all_q<-ddply(df.all,.(flag,dday),summarize,q10=quantile(comp_var,0.1,na.rm = T),q25=quantile(comp_var,0.25,na.rm = T),
q50=quantile(comp_var,0.5,na.rm = T),q75=quantile(comp_var,0.75,na.rm = T),q90=quantile(comp_var,0.9,na.rm = T))
#-----------------------
#add a additional test-->to compare if the vars are significant different(q50) in two categories
#----------------------
compare_diff<-function(df_comp,sel_perc,flag){
# df_comp<-df.all
# sel_perc<-1             #which period (percentage of the minimum days) used to compare between vars in two category
# flag<-"all"
df_comp_event<-df_comp[df_comp$flag=="SY_PSB",]
df_comp_nonevent<-df_comp[df_comp$flag=="SY_ASB",]
#------
#select the data
#------
range_dday_event<-range(df_comp_event$dday)
range_dday_nonevent<-range(df_comp_nonevent$dday)
range_sel<-c(min(range_dday_event[1],range_dday_nonevent[1]),
floor(sel_perc*min(range_dday_event[2],range_dday_nonevent[2])))
#
df_comp_event_sel<-subset(df_comp_event,dday>=range_sel[1]&dday<=range_sel[2])
df_comp_nonevent_sel<-subset(df_comp_nonevent,dday>=range_sel[1]&dday<=range_sel[2])
#additional-->for before events(b0):
df_comp_event_b0<-subset(df_comp_event,dday>=range_sel[1]&dday<=0)
df_comp_nonevent_b0<-subset(df_comp_nonevent,dday>=range_sel[1]&dday<=0)
#make the statistical comparision:
if(flag=="q50"){
stat.test_1<-difftest_function(df_comp_event_sel$q50,df_comp_nonevent_sel$q50)
stat.test_2<-difftest_function(df_comp_event_b0$q50,df_comp_nonevent_b0$q50)
stat.test<-cbind(stat.test_1,stat.test_2)
names(stat.test)<-c("All selecte period","Before events")
}
if(flag=="all"){
stat.test_1<-difftest_function(df_comp_event_sel$comp_var,df_comp_nonevent_sel$comp_var)
stat.test_2<-difftest_function(df_comp_event_b0$comp_var,df_comp_nonevent_b0$comp_var)
stat.test<-cbind(stat.test_1,stat.test_2)
names(stat.test)<-c("All selecte period","Before events")
}
return(stat.test)
}
#
stat.alldata_for2<-compare_diff(df.all,1,"all")
stat.q50_for2<-compare_diff(df.all_q,1,"q50")
#making the quantile plot using ribbon function:
p_plot<-ggplot(df.all_q)+
# annotate("rect",xmin=0,xmax=max(df.all_q$dday),ymin = -Inf,ymax = Inf,alpha=0.2)+
#some changes here
annotate("rect",xmin=0,xmax=70,ymin = -Inf,ymax = Inf,alpha=0.2)+
geom_line(aes(x=dday,y=q50,col=flag),size=1.05)+
scale_color_manual("",values = c("SY_PSB"="red","SY_ASB"="blue"))+
# geom_ribbon(aes(x=dday,ymin=q10,ymax=q90,fill=flag),alpha=0.15)+
geom_ribbon(aes(x=dday,ymin=q25,ymax=q75,fill=flag),alpha=0.4)+
scale_fill_manual("",values = c("SY_PSB"="red","SY_ASB"="dodgerblue"))+
ylab(paste0(comp_var," ",var_unit))+
xlab("gday")+
theme_classic()+
theme(legend.position = c(0.3,0.9),legend.background = element_blank(),
legend.key.size = unit(2, 'lines'),
legend.text = element_text(size=20),
axis.title = element_text(size=24),
axis.text = element_text(size = 20))+
xlim(-60,70)  #add x range in 2021-09-25
#legend
if(do_legend==FALSE){
p_plot<-p_plot+
theme(legend.position = "none")
}
# print(p_plot)
#returun object
out<-c()
out$stats_q50<-stat.q50_for2
out$stats_alldata<-stat.alldata_for2
out$plot<-p_plot
return(out)
}
#2021-09-25:check the temp_min,temp_max,temp_day, and LUE
#update in 2021-11-16:update the gpp_obs, gpp_biaes
#--------------
#I.GPP and LUE
#-------------
#gpp_obs
p_gpp_obs_len5_b60<-plot_2groups(df_len5_nonnorm,"gpp_obs","(umol m-2 s-1)",do_norm = FALSE,do_legend = TRUE)
#TS_top3-->mean of first 3 layers:
p_TS_1_len5_b60<-plot_2groups(df_len5_nonnorm,"TS_1_fluxnet2015","(degreeC)",do_norm = FALSE,FALSE)
#SWC_1-->first layer soil mosture
p_TS_2_len5_b60<-plot_2groups(df_len5_nonnorm,"TS_2_fluxnet2015","(%)",do_norm = FALSE,FALSE)
p_TS_3_len5_b60<-plot_2groups(df_len5_nonnorm,"TS_3_fluxnet2015","(%)",do_norm = FALSE,FALSE)
p_TS_top3_len5_b60<-plot_2groups(df_len5_nonnorm,"TS_top3_fluxnet2015","(%)",do_norm = FALSE,FALSE)
p_TS_top3_len5_b60$plot
rm(list=ls())
rm(list=ls())
setwd("D:/Github/Greenness_and_Treering/data-raw/data_from_ERA5/test/")
library(tidyverse)
library(openxlsx)
library(ncdf4)
install.packages("openxlsx")
library(raster)
library(sf)
## 读取nc4文件，看数据层次
# SOCdata <- nc_open("SOC_density_maps_in_China.nc4")
SWC_1<-nc_open("adaptor.mars.internal-1661437038.1201403-16407-10-6f029531-f70d-4204-8d96-86137fc4bb18.nc")
names(SWC_1)
SWC_1$nvars
SWC_1$var
source("~/photocold_manuscript/analysis/statistics/01_gpp_overestimation_stats.R")
df_norm_trs_newM_allover
source("~/photocold_manuscript/analysis/statistics/02_overestimation_stats_details_event_length.R")
df_events_all %>% View()
